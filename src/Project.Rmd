- add average difference in propensity scores for the 1-k matching

```{r}
# Import necessary libraries
library(haven)
library(DOS2)
library(optmatch)
library(RItools)
library(plyr)
library(dplyr)
library(rcbalance)
library(ggplot2)

# Import separate files
source("src/aipw.R")
source("src/data_filtering.R")
source("src/utility.R")

full_data <- read_dta('data/04599-0002-Data.dta')
```

```{r}
# list of outcomes we may want to study
# the ones from the paper are "SEGRADES", "SEBEHAVR", "SESCHLWR"
outcomes <- c("SEGRADES", "SEBEHAVR", "SESCHLWR")
# outcomes <- c("SEGRADES", "SEBEHAVR", "SESCHLWR", "SEGRADEQ", "SESUSOUT", "SESUSPIN")

# list of covariates we choose to take into account
# sex, age, race/ethnicity, mothers' educational levels, mothers' marital status, childcare subsidy, and community levels
covariates <- c("SEX", "AGE2004", "RACEETHN", "MOMEDUC", "MOMSTAT", "ZIPURB")

# variables we can use for sample selection and stuff
others <- c("SCHLTYPE", "MOMEMPLD", "HINCOME", "ANYCARE", "HOMESCHL", "HH18OVER", "HHTOTAL", "HHUNDR18", "CENREG")

# select the sample used for study
# NB in the paper they are left with 717 units in their sample
dat <- filter_and_clean(full_data, verbose = 1)

perform_sanity_checks(dat)
```




ATE estimation of academic score
```{r}
# preprocess data for logistic regression
lr_data <- dat
# change values in binary columns to 1 and 0
lr_data$SCSELF[lr_data$SCSELF == 2] <- 0
lr_data$SCSELF[lr_data$RCNOW == 2] <- 0
lr_data$SCSELF[lr_data$CPSNOW == 2] <- 0
lr_data$SCSELF[lr_data$PAAHOME == 2] <- 0
lr_data$HGOVCUR[lr_data$HGOVCUR == 2] <- 0


summary(glm(SEGRADES ~ SCSELF + RCNOW + CPSNOW + PAAHOME + as.factor(SEX) + AGE2004 + as.factor(RACEETHN) + as.factor(MOMEDUC) + as.factor(MOMSTAT) + as.factor(ZIPURB) + HGOVCUR, data=lr_data))
# In the paper, the coefficient is 0.18 and standard deviation is 0.33. 
```


as.factor
```{r}
# factor categorical variables - not working
# dat$RACEETHN <- as.factor(dat$RACEETHN)
# dat$MOMEDUC <- as.factor(dat$MOMEDUC)
# dat$MOMSTAT <- as.factor(dat$MOMSTAT)
```

PART A: Exploratory data analysis

```{r}
# some plots

# balance of the covariates
plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB -1, strata= list(unstrat=NULL), data=dat))

# histogram of MOMSTAT, the most imbalanced covariate, in control and treatment groups
ggplot(dat, aes(x=MOMSTAT, fill = as.factor(HGOVCUR)))+
   geom_histogram( color='#e9ecef', alpha=0.4, position='identity', bins = 5)
ggtitle("Histogram of the edm and faminc covariates")

# estimation of the propensity score 
dat$prop <- glm(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB, family=binomial, 
                data=dat)$fitted.values
ggplot(dat, aes(x=prop, fill = as.factor(HGOVCUR))) + geom_density(alpha=0.4) + 
  ggtitle("Distribution of the propensity score")
```

PART B: Pairwise matching

```{r}
#matched pair set using Mahalanobis distance, w/o caliper
mat.1 <- smahal(dat$HGOVCUR, dat[,c("SEX", "AGE2004", "RACEETHN", "MOMEDUC", "MOMSTAT", "ZIPURB")]) 
ms.1 <- pairmatch(mat.1, data=dat)
adat.1 <- summarize.match(dat, ms.1)
```

```{r}
# average absolute difference in propensity score, before caliper matching
mean(abs(adat.1$prop.1-adat.1$prop.0))
# max absolute difference
max(abs(adat.1$prop.1-adat.1$prop.0))
```

```{r}
# matched pair set using Mahalanobis distance, w/ caliper
mat.2 <- addcaliper(mat.1, z=dat$HGOVCUR, p=dat$prop, caliper=0.1)
ms.2 <- pairmatch(mat.2, data=dat)
adat.2 <- summarize.match(dat,ms.2)
```

```{r}
# covariate balance before and after caliper matching
plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB + prop- 1, 
            strata=list(unstrat=NULL, ms.2=~ms.2),
              data=dat)) 
```

```{r}
# average absolute difference in propensity score, before caliper matching
mean(abs(adat.2$prop.1-adat.2$prop.0))
# max absolute difference
max(abs(adat.2$prop.1-adat.2$prop.0))
```

PART C: 1 to k matching

```{r}
# match each treated to 5 controls, w/ caliper
mat.3 <- addcaliper(mat.1, z=dat$HGOVCUR, p=dat$prop, caliper=0.1)
ms.3 <- pairmatch(mat.3, controls = 5, data=dat)

# covariate balance before and after 1-5 matching
plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB + prop - 1,
              strata=list(unstrat=NULL, ms.3=~ms.3),
              data=dat))
```


```{r}
# force balance on MOMSTAT
mat.4 <- addalmostexact(mat.3, z=dat$HGOVCUR, f=dat$MOMSTAT, mult=5) 
ms.4 <- pairmatch(mat.4, controls = 5, data=dat)

# compare balance before and after forcing balance
plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB + prop - 1,
              strata=list(unstrat=NULL, ms.3=~ms.3),
              data=dat))

plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB + prop - 1,
              strata=list(unstrat=NULL, ms.4=~ms.4),
              data=dat))
```

```{r}
# match each treated to 15 controls, w/ caliper
mat.5 <- addcaliper(mat.1, z=dat$HGOVCUR, p=dat$prop, caliper=0.1) # same caliper as before, different name
ms.5 <- pairmatch(mat.5, controls = 12, data=dat)

# covariate balance before and after 1-15 matching
plot(xBalance(HGOVCUR ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB + prop - 1,
              strata=list(unstrat=NULL, ms.5=~ms.5),
              data=dat))
```

Post-matching analysis

```{r}
# p-value from an FRT of Fisher's sharp null from the 1:1 matched data set

# Annie's code ---- 
mat1 <- smahal(dat$HGOVCUR, dat[, covariates])
mat2 <- addcaliper(mat1, z=dat$HGOVCUR, p=dat$prop, caliper=.1)
pairs2 <- pairmatch(mat2, data = dat)
mat_sum <- summarize.match(dat, pairs2)
obs_te <- mat_sum$SEGRADES.1 - mat_sum$SEGRADES.0
obs_ate <- mean(obs_te)

N <- 1000
simulation_lst <- list()
for (i in 1:N){
  sim_Z <- sample(c(-1, 1), nrow(mat_sum), replace = TRUE, prob = c(0.5, 0.5))
  sim_ate <- mean(sim_Z * obs_te)
  simulation_lst <- append(simulation_lst, sim_ate)
}
p_value <- mean(simulation_lst >= obs_ate)
sprintf("The p-value is %.3f.", p_value)
```

```{r}
# Paul's code ---
generate_random_vector <- function(n) {
    random_vector <- sample(c(1, -1), n, replace = TRUE)
    return(random_vector)
}
observed_ate <- mean(adat.1$SEGRADES.1 - adat.1$SEGRADES.0)
n_pairs <- nrow(adat.1)
n_simulations <- 1000

# y = SEGRADES
count <- 0
for (i in 1:n_simulations) {
    permutation <- generate_random_vector(n_pairs)
    simulated_ate <- mean((adat.1$SEGRADES.1 - adat.1$SEGRADES.0) * permutation)
    if (simulated_ate > observed_ate) {
        count <- count + 1
    }
}
p_value <- count / n_simulations
p_value
```

```{r}
# bias corrected estimate of the ATE on the treated and its variance

# Raphaelle's code ---------
n1 <- nrow(adat.1)
fit1 <- lm(SEGRADES.1 ~ adat.1$SEX.1 + adat.1$AGE2004.1 + adat.1$RACEETHN.1 + 
             adat.1$MOMEDUC.1 + adat.1$MOMSTAT.1 + adat.1$ZIPURB.1, data=adat.1)
fit0 <- lm(SEGRADES.0 ~ adat.1$SEX.0 + adat.1$AGE2004.0 + adat.1$RACEETHN.0 + 
             adat.1$MOMEDUC.0 + adat.1$MOMSTAT.0 + adat.1$ZIPURB.0, data=adat.1)
match0 <- adat.1[, seq(1, ncol(adat.1)-1, by = 2)]
match1 <- adat.1[, seq(2, ncol(adat.1), by = 2)]
match0 <- rename_at(match0,.vars = vars(ends_with(".0")),.funs = funs(sub("[.]0$", "", .)))
match1 <- rename_at(match1,.vars = vars(ends_with(".1")),.funs = funs(sub("[.]1$", "", .)))
mu0hat <- predict(fit0,match1)
mu1hat <- predict(fit1,match0)
taum <- mean(adat.1$SEGRADES.1-adat.1$SEGRADES.0)
bias <- sum(mu0hat - mu1hat)/n1
vhat <- sum((adat.1$SEGRADES.1 - mu1hat)^2 + (adat.1$SEGRADES.0 - mu0hat)^2)/n1^2

taum - bias
vhat
```


```{r}
# Paul's code ---------
mahal_distance <- smahal(dat$HGOVCUR, dat[, covariates])
distance <- addcaliper(mahal_distance, z = dat$HGOVCUR, p = dat$prop, caliper = 0.1)

pair_matching <- pairmatch(distance, data = dat)
matching_summary <- summarize.match(dat, pair_matching)

train_control <- matching_summary[, c("SEGRADES.1", "SEGRADES.0")]
train_control$SEX <- matching_summary$SEX.0
train_control$AGE2004 <- matching_summary$AGE2004.0
train_control$RACEETHN <- matching_summary$RACEETHN.0
train_control$MOMEDUC <- matching_summary$MOMEDUC.0
train_control$MOMSTAT <- matching_summary$MOMSTAT.0
train_control$ZIPURB <- matching_summary$ZIPURB.0

train_treatment <- matching_summary[, c("SEGRADES.1", "SEGRADES.0")]
train_treatment$SEX <- matching_summary$SEX.1
train_treatment$AGE2004 <- matching_summary$AGE2004.1
train_treatment$RACEETHN <- matching_summary$RACEETHN.1
train_treatment$MOMEDUC <- matching_summary$MOMEDUC.1
train_treatment$MOMSTAT <- matching_summary$MOMSTAT.1
train_treatment$ZIPURB <- matching_summary$ZIPURB.1

# Create the estimators for E[Y | Z = z, X = x]
# mu_0 <- lm(y.0 ~ afqtpct + black + edm + faminc + female + hisp + incmiss, data <- train_control)
mu_0 <- lm(SEGRADES.0 ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB, data <- train_control)
# mu_1 <- lm(y.1 ~ afqtpct + black + edm + faminc + female + hisp + incmiss, data <- train_treatment)
mu_1 <- lm(SEGRADES.1 ~ SEX + AGE2004 + RACEETHN + MOMEDUC + MOMSTAT + ZIPURB, data <- train_control)
summary(mu_0)
summary(mu_1)

# Compute bias estimator
# we note that J_i contains only one unit since we are working with pairs
bias <- mean(predict(mu_0, train_treatment) - predict(mu_0, train_control))

unbiased_ate <- observed_ate - bias

variance <- sum((matching_summary$SEGRADES.1 - predict(mu_1, train_treatment))^2
                 + (matching_summary$SEGRADES.0 - predict(mu_0, train_control))^2) / nrow(matching_summary)^2

unbiased_ate
variance
```

```{r}
# Annie's code ---------
mat1 <- smahal(dat$HGOVCUR, dat[, outcomes])
mat2 <- addcaliper(mat1, z=dat$HGOVCUR, p=dat$prop, caliper=.1)
pairs2 <- pairmatch(mat2, data = dat)
mat_sum <- summarize.match(dat, pairs2)
n1 <- nrow(mat_sum)

fit <- lm(SEGRADES.0 ~ SEX.0 + AGE2004.0 + RACEETHN.0 + MOMEDUC.0 + MOMSTAT.0 + ZIPURB.0, data = mat_sum)
mu_0_xmi <- predict(fit, mat_sum[c("SEX.0", "AGE2004.0", "RACEETHN.0", "MOMEDUC.0", "MOMSTAT.0", "ZIPURB.0")])
mat_sum_t <- mat_sum[c("SEX.1", "AGE2004.1", "RACEETHN.1", "MOMEDUC.1", "MOMSTAT.1", "ZIPURB.1")]
names(mat_sum_t) <- c("SEX.0", "AGE2004.0", "RACEETHN.0", "MOMEDUC.0", "MOMSTAT.0", "ZIPURB.0")
mu_0_xi <- predict(fit, mat_sum_t)
n1 <- nrow(mat_sum)
tau_hat <- mean((mat_sum$SEGRADES.1 - mat_sum$SEGRADES.0) - (mu_0_xi - mu_0_xmi))
tau_hat

fit1 <- lm(SEGRADES.1 ~ faminc.1 + incmiss.1 + black.1 + hisp.1 + afqtpct.1 + edmissm.1 + edm.1 + female.1, data = mat_sum)
mu_1_xi <- predict(fit1, mat_sum[c("SEX.1", "AGE2004.1", "RACEETHN.1", "MOMEDUC.1", "MOMSTAT.1", "ZIPURB.1")])
V_hat <- sum((mat_sum$SEGRADES.1 - mu_1_xi)^2 + (mat_sum$SEGRADES.0 - mu_0_xmi)^2) / n1^2
V_hat
```
AIPW estimator
```{r}
# limit sample to people who were treatment or control
# make HGOVCUR binary in {0,1} instead of {1,2}
# aipw_data <- subset(full_data, HGOVCUR == 1 | HGOVCUR == 2)
# aipw_data$HGOVCUR <- ifelse(aipw_data$HGOVCUR == 1, 1, 0)
# aipw_data <- subset(lr_data, HGOVCUR >= 0)
source("src/aipw.R")
dat <- filter_and_clean(full_data, verbose = 1)
aipw_data <- dat

aipw <- aipw_analysis(aipw_data, n_bootstrap = 100)
aipw
aipw_ate <- aipw[1]
aipw_var <- aipw[2]
```
